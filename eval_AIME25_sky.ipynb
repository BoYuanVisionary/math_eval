{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb65588515b476eb6240c5add530e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/817 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-14 21:16:52 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 02-14 21:16:52 config.py:1020] Defaulting to use mp for distributed inference\n",
      "INFO 02-14 21:16:52 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='NovaSky-AI/Sky-T1-32B-Preview', speculative_config=None, tokenizer='NovaSky-AI/Sky-T1-32B-Preview', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NovaSky-AI/Sky-T1-32B-Preview, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954825c5189241d2927a45a24d80e4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3a83c8000e4c3fa9297fe6d6e8df9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e102877253247a5ba3b86514dd86bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497b2d1f7eeb4cff9ae758758252fe83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb02cfdf64924350890f676dce454180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e82f0e3edca4be7a77e6ad0a4db2979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-14 21:16:54 multiproc_gpu_executor.py:56] Reducing Torch parallelism from 8 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 02-14 21:16:54 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "INFO 02-14 21:16:54 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m INFO 02-14 21:16:54 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m INFO 02-14 21:16:54 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m INFO 02-14 21:16:54 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m INFO 02-14 21:16:54 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m INFO 02-14 21:16:54 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m INFO 02-14 21:16:54 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 02-14 21:16:56 utils.py:961] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m INFO 02-14 21:16:56 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m INFO 02-14 21:16:56 utils.py:961] Found nccl from library libnccl.so.2\n",
      "INFO 02-14 21:16:56 utils.py:961] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m INFO 02-14 21:16:56 utils.py:961] Found nccl from library libnccl.so.2\n",
      "INFO 02-14 21:16:56 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 02-14 21:16:56 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m INFO 02-14 21:16:56 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "WARNING 02-14 21:16:57 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m WARNING 02-14 21:16:57 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 02-14 21:16:57 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 02-14 21:16:57 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 02-14 21:16:57 shm_broadcast.py:236] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fe319e463a0>, local_subscribe_port=43467, remote_subscribe_port=None)\n",
      "INFO 02-14 21:16:57 model_runner.py:1072] Starting to load model NovaSky-AI/Sky-T1-32B-Preview...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m INFO 02-14 21:16:57 model_runner.py:1072] Starting to load model NovaSky-AI/Sky-T1-32B-Preview...\n",
      "INFO 02-14 21:16:57 model_runner.py:1072] Starting to load model NovaSky-AI/Sky-T1-32B-Preview...\n",
      "INFO 02-14 21:16:57 model_runner.py:1072] Starting to load model NovaSky-AI/Sky-T1-32B-Preview...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] Exception in worker VllmWorkerProcess while processing method load_model.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] Traceback (most recent call last):\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/multiproc_worker_utils.py\", line 223, in _run_worker_process\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     output = executor(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/worker.py\", line 152, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model_runner.load_model()\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/model_runner.py\", line 1074, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model = get_model(vllm_config=self.vllm_config)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] Exception in worker VllmWorkerProcess while processing method load_model.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/__init__.py\", line 12, in get_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return loader.load_model(vllm_config=vllm_config)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 332, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     model = _initialize_model(vllm_config=vllm_config)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 100, in _initialize_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] Traceback (most recent call last):\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 430, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/multiproc_worker_utils.py\", line 223, in _run_worker_process\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model = Qwen2Model(vllm_config=vllm_config,\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     output = executor(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/compilation/decorators.py\", line 126, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/worker.py\", line 152, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] Exception in worker VllmWorkerProcess while processing method load_model.\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 279, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model_runner.load_model()\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] Traceback (most recent call last):\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 509, in make_layers\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/multiproc_worker_utils.py\", line 223, in _run_worker_process\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/model_runner.py\", line 1074, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     output = executor(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 510, in <listcomp>\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/worker.py\", line 152, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model_runner.load_model()\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model = get_model(vllm_config=self.vllm_config)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 281, in <lambda>\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/__init__.py\", line 12, in get_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/model_runner.py\", line 1074, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     lambda prefix: Qwen2DecoderLayer(config=config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model = get_model(vllm_config=self.vllm_config)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 201, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return loader.load_model(vllm_config=vllm_config)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/__init__.py\", line 12, in get_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.mlp = Qwen2MLP(\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 332, in load_model\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return loader.load_model(vllm_config=vllm_config)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 69, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     model = _initialize_model(vllm_config=vllm_config)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 332, in load_model\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.gate_up_proj = MergedColumnParallelLinear(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     model = _initialize_model(vllm_config=vllm_config)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 424, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 100, in _initialize_model\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 100, in _initialize_model\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     super().__init__(input_size=input_size,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 304, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.quant_method.create_weights(\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 430, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 430, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model = Qwen2Model(vllm_config=vllm_config,\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 122, in create_weights\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.model = Qwen2Model(vllm_config=vllm_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/compilation/decorators.py\", line 126, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/compilation/decorators.py\", line 126, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     weight = Parameter(torch.empty(sum(output_partition_sizes),\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 279, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 279, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/torch/utils/_device.py\", line 106, in __torch_function__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return func(*args, **kwargs)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 509, in make_layers\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330906)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 509, in make_layers\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 1 has a total capacity of 47.43 GiB of which 15.00 MiB is free. Process 91091 has 40.94 GiB memory in use. Including non-PyTorch memory, this process has 6.46 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 55.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 510, in <listcomp>\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 510, in <listcomp>\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 281, in <lambda>\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 281, in <lambda>\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     lambda prefix: Qwen2DecoderLayer(config=config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     lambda prefix: Qwen2DecoderLayer(config=config,\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 201, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 201, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.mlp = Qwen2MLP(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.mlp = Qwen2MLP(\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 69, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py\", line 69, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.gate_up_proj = MergedColumnParallelLinear(\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.gate_up_proj = MergedColumnParallelLinear(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 424, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 424, in __init__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     super().__init__(input_size=input_size,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     super().__init__(input_size=input_size,\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 304, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.quant_method.create_weights(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 122, in create_weights\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 304, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     weight = Parameter(torch.empty(sum(output_partition_sizes),\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     self.quant_method.create_weights(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/torch/utils/_device.py\", line 106, in __torch_function__\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py\", line 122, in create_weights\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return func(*args, **kwargs)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     weight = Parameter(torch.empty(sum(output_partition_sizes),\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330907)\u001b[0;0m \u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 2 has a total capacity of 47.43 GiB of which 15.00 MiB is free. Process 91092 has 40.94 GiB memory in use. Including non-PyTorch memory, this process has 6.46 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 55.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]   File \"/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/torch/utils/_device.py\", line 106, in __torch_function__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=330908)\u001b[0;0m ERROR 02-14 21:16:57 multiproc_worker_utils.py:229] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 3 has a total capacity of 47.43 GiB of which 135.00 MiB is free. Process 91093 has 40.86 GiB memory in use. Including non-PyTorch memory, this process has 6.42 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 55.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 47.43 GiB of which 13.00 MiB is free. Process 88216 has 40.98 GiB memory in use. Including non-PyTorch memory, this process has 6.42 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 53.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNovaSky-AI/Sky-T1-32B-Preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m tok \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNovaSky-AI/Sky-T1-32B-Preview\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m stop_token_ids \u001b[38;5;241m=\u001b[39m tok(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|im_end|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/utils.py:1028\u001b[0m, in \u001b[0;36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1023\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1024\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1025\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m         )\n\u001b[0;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/entrypoints/llm.py:210\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_overrides, mm_processor_kwargs, task, override_pooler_config, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_engine_class()\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# TODO(rob): enable mp by default (issue with fork vs spawn)\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/engine/llm_engine.py:585\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    583\u001b[0m executor_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_executor_cls(engine_config)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/engine/llm_engine.py:347\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, mm_registry, use_cached_outputs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_registry \u001b[38;5;241m=\u001b[39m input_registry\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_processor \u001b[38;5;241m=\u001b[39m input_registry\u001b[38;5;241m.\u001b[39mcreate_input_processor(\n\u001b[1;32m    345\u001b[0m     model_config)\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/distributed_gpu_executor.py:26\u001b[0m, in \u001b[0;36mDistributedGPUExecutor.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Updated by implementations that require additional args to be passed\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# to the _run_workers execute_model call\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_execute_model_run_workers_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/executor_base.py:36\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, vllm_config)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_adapter_config \u001b[38;5;241m=\u001b[39m vllm_config\u001b[38;5;241m.\u001b[39mprompt_adapter_config\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;241m=\u001b[39m vllm_config\u001b[38;5;241m.\u001b[39mobservability_config\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/multiproc_gpu_executor.py:114\u001b[0m, in \u001b[0;36mMultiprocessingGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_worker(\n\u001b[1;32m    112\u001b[0m     distributed_init_method\u001b[38;5;241m=\u001b[39mdistributed_init_method)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_workers(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_concurrent_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_parallel_loading_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/executor/multiproc_gpu_executor.py:195\u001b[0m, in \u001b[0;36mMultiprocessingGPUExecutor._run_workers\u001b[0;34m(self, method, async_run_tensor_parallel_workers_only, max_concurrent_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m worker_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    190\u001b[0m     worker\u001b[38;5;241m.\u001b[39mexecute_method(method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[1;32m    192\u001b[0m ]\n\u001b[1;32m    194\u001b[0m driver_worker_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker, method)\n\u001b[0;32m--> 195\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m \u001b[43mdriver_worker_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Get the results of the workers.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [driver_worker_output\n\u001b[1;32m    199\u001b[0m         ] \u001b[38;5;241m+\u001b[39m [output\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m worker_outputs]\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/worker.py:152\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/worker/model_runner.py:1074\u001b[0m, in \u001b[0;36mGPUModelRunnerBase.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1072\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to load model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DeviceMemoryProfiler() \u001b[38;5;28;01mas\u001b[39;00m m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mconsumed_memory\n\u001b[1;32m   1077\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model weights took \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1078\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m))\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/__init__.py:12\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(vllm_config)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;241m*\u001b[39m, vllm_config: VllmConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m     11\u001b[0m     loader \u001b[38;5;241m=\u001b[39m get_model_loader(vllm_config\u001b[38;5;241m.\u001b[39mload_config)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py:332\u001b[0m, in \u001b[0;36mDefaultModelLoader.load_model\u001b[0;34m(self, vllm_config)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_default_torch_dtype(model_config\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m target_device:\n\u001b[0;32m--> 332\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43m_initialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_weights(model_config, model))\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py:100\u001b[0m, in \u001b[0;36m_initialize_model\u001b[0;34m(vllm_config, prefix)\u001b[0m\n\u001b[1;32m     97\u001b[0m all_params \u001b[38;5;241m=\u001b[39m [param\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvllm_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_params \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_params:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# new-style model class\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvLLM model class should accept `vllm_config` and `prefix` as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput arguments. Possibly you have an old-style model class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m registered from out of tree and it is used for new vLLM version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck https://docs.vllm.ai/en/latest/design/class_hierarchy.html \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the design and update the model class accordingly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(msg)\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py:430\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.__init__\u001b[0;34m(self, vllm_config, prefix)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config \u001b[38;5;241m=\u001b[39m lora_config\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config \u001b[38;5;241m=\u001b[39m quant_config\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mQwen2Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed_tokens\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/compilation/decorators.py:126\u001b[0m, in \u001b[0;36m_support_torch_compile.<locals>.__init__\u001b[0;34m(self, vllm_config, prefix, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, vllm_config: VllmConfig, prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mold_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# for CompilationLevel.DYNAMO_AS_IS , the upper level model runner\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# will handle the compilation, so we don't need to do anything here.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_compile \u001b[38;5;241m=\u001b[39m envs\u001b[38;5;241m.\u001b[39mVLLM_TORCH_COMPILE_LEVEL \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    130\u001b[0m         CompilationLevel\u001b[38;5;241m.\u001b[39mNO_COMPILATION, CompilationLevel\u001b[38;5;241m.\u001b[39mDYNAMO_AS_IS\n\u001b[1;32m    131\u001b[0m     ] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m supports_dynamo()\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py:279\u001b[0m, in \u001b[0;36mQwen2Model.__init__\u001b[0;34m(self, vllm_config, prefix)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m PPMissingLayer()\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m \u001b[43mmake_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQwen2DecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.layers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.layers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_empty_intermediate_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    289\u001b[0m     make_empty_intermediate_tensors_factory(\n\u001b[1;32m    290\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m\"\u001b[39m], config\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py:509\u001b[0m, in \u001b[0;36mmake_layers\u001b[0;34m(num_hidden_layers, layer_fn, prefix)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pp_indices\n\u001b[1;32m    505\u001b[0m start_layer, end_layer \u001b[38;5;241m=\u001b[39m get_pp_indices(num_hidden_layers,\n\u001b[1;32m    506\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mrank_in_group,\n\u001b[1;32m    507\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mworld_size)\n\u001b[1;32m    508\u001b[0m modules \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 509\u001b[0m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m    510\u001b[0m         maybe_offload_to_cpu(layer_fn(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer, end_layer)\n\u001b[1;32m    512\u001b[0m     ] \u001b[38;5;241m+\u001b[39m [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/utils.py:510\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pp_indices\n\u001b[1;32m    505\u001b[0m start_layer, end_layer \u001b[38;5;241m=\u001b[39m get_pp_indices(num_hidden_layers,\n\u001b[1;32m    506\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mrank_in_group,\n\u001b[1;32m    507\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mworld_size)\n\u001b[1;32m    508\u001b[0m modules \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    509\u001b[0m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m--> 510\u001b[0m         maybe_offload_to_cpu(\u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer, end_layer)\n\u001b[1;32m    512\u001b[0m     ] \u001b[38;5;241m+\u001b[39m [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py:281\u001b[0m, in \u001b[0;36mQwen2Model.__init__.<locals>.<lambda>\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m PPMissingLayer()\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m make_layers(\n\u001b[1;32m    280\u001b[0m     config\u001b[38;5;241m.\u001b[39mnum_hidden_layers,\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m prefix: \u001b[43mQwen2DecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.layers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    285\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.layers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_empty_intermediate_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    289\u001b[0m     make_empty_intermediate_tensors_factory(\n\u001b[1;32m    290\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m\"\u001b[39m], config\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py:190\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.__init__\u001b[0;34m(self, config, cache_config, quant_config, prefix)\u001b[0m\n\u001b[1;32m    188\u001b[0m rope_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_theta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1000000\u001b[39m)\n\u001b[1;32m    189\u001b[0m rope_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_scaling\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mQwen2Attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_kv_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_key_value_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrope_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.self_attn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m Qwen2MLP(\n\u001b[1;32m    202\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    203\u001b[0m     intermediate_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mintermediate_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    209\u001b[0m                                eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/models/qwen2.py:129\u001b[0m, in \u001b[0;36mQwen2Attention.__init__\u001b[0;34m(self, hidden_size, num_heads, num_kv_heads, max_position, rope_theta, cache_config, quant_config, rope_scaling, prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrope_theta \u001b[38;5;241m=\u001b[39m rope_theta\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv_proj \u001b[38;5;241m=\u001b[39m \u001b[43mQKVParallelLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_num_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_num_kv_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.qkv_proj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj \u001b[38;5;241m=\u001b[39m RowParallelLinear(\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_num_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim,\n\u001b[1;32m    140\u001b[0m     hidden_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.o_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb \u001b[38;5;241m=\u001b[39m get_rope(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim,\n\u001b[1;32m    148\u001b[0m     rotary_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     rope_scaling\u001b[38;5;241m=\u001b[39mrope_scaling,\n\u001b[1;32m    152\u001b[0m )\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py:681\u001b[0m, in \u001b[0;36mQKVParallelLinear.__init__\u001b[0;34m(self, hidden_size, head_size, total_num_heads, total_num_kv_heads, bias, skip_bias_add, params_dtype, quant_config, prefix)\u001b[0m\n\u001b[1;32m    673\u001b[0m output_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    674\u001b[0m                \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_kv_heads) \u001b[38;5;241m*\u001b[39m tp_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_sizes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size \u001b[38;5;241m*\u001b[39m tp_size,  \u001b[38;5;66;03m# q_proj\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_kv_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size \u001b[38;5;241m*\u001b[39m tp_size,  \u001b[38;5;66;03m# k_proj\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_kv_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size \u001b[38;5;241m*\u001b[39m tp_size,  \u001b[38;5;66;03m# v_proj \u001b[39;00m\n\u001b[1;32m    679\u001b[0m ]\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mgather_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mskip_bias_add\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bias_add\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py:304\u001b[0m, in \u001b[0;36mColumnParallelLinear.__init__\u001b[0;34m(self, input_size, output_size, bias, gather_output, skip_bias_add, params_dtype, quant_config, output_sizes, prefix)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     output_sizes \u001b[38;5;241m=\u001b[39m [output_size]\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_loader_v2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mWEIGHT_LOADER_V2_SUPPORTED\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m    316\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size_per_partition,\n\u001b[1;32m    317\u001b[0m                     dtype\u001b[38;5;241m=\u001b[39mparams_dtype))\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/vllm/model_executor/layers/linear.py:122\u001b[0m, in \u001b[0;36mUnquantizedLinearMethod.create_weights\u001b[0;34m(self, layer, input_size_per_partition, output_partition_sizes, input_size, output_size, params_dtype, **extra_weight_attrs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m    118\u001b[0m                    input_size_per_partition: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    119\u001b[0m                    output_partition_sizes: List[\u001b[38;5;28mint\u001b[39m], input_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    120\u001b[0m                    output_size: \u001b[38;5;28mint\u001b[39m, params_dtype: torch\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    121\u001b[0m                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_weight_attrs):\n\u001b[0;32m--> 122\u001b[0m     weight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    125\u001b[0m                        requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    126\u001b[0m     set_weight_attrs(weight, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m})\n\u001b[1;32m    127\u001b[0m     layer\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight)\n",
      "File \u001b[0;32m/ssdscratch/byuan48/software/anaconda3/envs/reasoning/lib/python3.9/site-packages/torch/utils/_device.py:106\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 47.43 GiB of which 13.00 MiB is free. Process 88216 has 40.98 GiB memory in use. Including non-PyTorch memory, this process has 6.42 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 53.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the model\n",
    "llm = LLM(\n",
    "    model=\"GAIR/LIMO\",\n",
    "    tensor_parallel_size=4,  # adjust based on available GPUs\n",
    "    trust_remote_code=True,\n",
    "    swap_space=60,\n",
    "    gpu_memory_utilization=0.96,\n",
    ")\n",
    "\n",
    "# Prepare input messages (We use the following template and system prompt during training and inference)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the result of 1+1?\"}\n",
    "]\n",
    "\n",
    "# Setup tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GAIR/LIMO\", trust_remote_code=True)\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Configure generation parameters\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.7,\n",
    "    max_tokens=32768,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "# Generate response\n",
    "output = llm.generate(text, sampling_params)\n",
    "print(output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
